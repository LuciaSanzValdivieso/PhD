#### IN MONOLINGUAL SAMPLE, WITH BILINGUAL TERMLIST #### 6.3.1

# To keep only the source expressions from a bilingual termlist that has the format "source expression, tab, target expression":
	cut -f1 bil-termlist.txt > mono-termlist.txt

# To identify the glossary Spanish (source) terms in a monolingual Spanish sample. Two outputs: terms and segments where they are, both with counts.
	python3 monoterm-check-2output.py monol-corpus.txt mono-termlist.txt output-mono-terms.txt output-mono-segments.txt 
	# To sum the counts in output-terms.txt and know types/tokens:
		python3 sum-numbers-mono.py --file output-mono-terms.txt --output sum-output-mono-terms.txt

	# To strip the numbers from the term output file for the next step:
	cut -f1 output-mono-terms.txt > termsinsample-monol.txt

	#To identify the equivalences prescribed by the glossary/bilingual termlist for those terms present in the monolingual source corpus, 
	# i.e., the expected correct equivalences to look for in the translations:
		python3 matchmonotermstobilglossary.py --file1 bil-termlist.txt --file2 termsinsample-monol.txt --output termsinsample-bil.txt



#### IN BILINGUAL SAMPLE/TRANSLATIONS and PARALLEL TRAINING DATASETS, WITH BILINGUAL TERMLIST OF TERMS IN SAMPLE (from previous step) #### 
#### REPEAT WITH EACH SYSTEMS' TRANSLATIONS and WITH DIFFERENT DATASETS, TO GET COUNTS (6.3.1 with translations, 6.3.2 with training datasets)
# To see what terms from the bilingual glossary are in the translations/training datasets, and you get again two outputs, 
# one counting pairs of equivalences, and one printing all segments with a count of the terms occuring in each segment.
	python3 paraterm-check-2outputs.py translation.txt/datasetAnotB.txt termsinsample-bil.txt outputsampleintrainingAnotB-terms.txt outputsampleintrainingAnotB-segments.txt
	### The first output file xyz-terms.txt has "SL expression, tab, TL expression, tab, occurrences" format, to be used for ANALYSIS explained below

	#To count source terms and not pairs of equivalences 
	#(en nariz as a single type, and not en nariz=on the nose and en nariz=in the nose as two types), edit collapsing-repeated-slterms.py
		python3 collapsing-repeated-slterms.py [will join lines with matching Spanish and different target, and sum counts of both]

		# In second output file, segments: first count how many 0 matches, then deduct from total line count (total segments) (wc -l):
			grep "0 matches" outputsampleintrainingAnotB-segments.txt | wc -l
			wc -l outputsampleintrainingAnotB-segments.txt

# In first output file (-terms): to get a sum of all the occurrences of all terms (tokens):
	python3 sum-numbers.py --file outputsampleintrainingAnotB-terms.txt --output sum-outputsampleintrainingAnotB.txt
# Count lines to know how many different terms (types):
	wc -l outputsampleintrainingAnotB-terms.txt
# Count how many terms occur once, twice, thrice, etc. in the format "occurrences: numbers of terms occuring that many times": (NOT USED IN DISSERTATION)
	python3 counter-occurrences.py --file outputsampleintrainingAnotB-terms.txt --output countsAnotB.txt

# To take out the number in the "expression, tab, expression, ta, count" -term.txt files, do:
	cut -f1,2 outputsampleinGoogle-terms.txt > outputsampleinGoogle-terms-nonum.txt

